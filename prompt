# Phase 1 Implementation Prompt: Energy Auction Core Engine

## Context & Current State

You are implementing Phase 1 of a complete rewrite of an energy auction smart contract on Solana using Anchor framework. The current MVP has fundamental flaws:

1. **No actual auction algorithm** - clearing prices are manually set by authority
2. **Broken multi-seller support** - assumes single seller in critical paths
3. **Incomplete bid processing** - bids are stored but never processed
4. **Manual settlement flows** - everything requires authority intervention

**CRITICAL: Read and understand the existing codebase thoroughly before proposing ANY changes. The provided code shows the current broken state - your job is to build a complete auction engine that replaces the flawed manual processes.**

## Your Specific Task: Build Core Auction Engine

Implement a complete, automated auction clearing system that:
- Processes all bids algorithmically to find clearing price
- Handles multiple sellers with proper merit order
- Executes atomic settlement without manual intervention
- Maintains mathematical correctness under all conditions

## Implementation Requirements

### 1. Auction Clearing Algorithm

**Implement these NEW instructions (do not modify existing broken ones):**

```rust
// Main clearing instruction - replaces manual settle_timeslot
pub fn execute_auction_clearing(
    ctx: Context<ExecuteAuctionClearing>,
    max_iterations: u16, // prevent infinite loops
) -> Result<ClearingResult>

// Supporting instructions for batch processing
pub fn process_bid_batch(
    ctx: Context<ProcessBidBatch>, 
    start_page: u32,
    end_page: u32,
) -> Result<BatchResult>

pub fn process_supply_batch(
    ctx: Context<ProcessSupplyBatch>,
    seller_keys: Vec<Pubkey>,
) -> Result<SupplyAllocationResult>
```

**Algorithm Requirements:**
- **Demand Curve Construction**: Iterate through ALL bid pages, extract bids, sort by price descending
- **Supply Curve Construction**: Fetch ALL supply commitments, sort by reserve price ascending (merit order)
- **Market Clearing**: Find intersection where cumulative demand >= cumulative supply
- **Quantity Allocation**: Distribute available supply to winning bids (highest price first)
- **Partial Fill Handling**: Handle cases where clearing price creates partial fills

### 2. Data Structure Overhaul

**Problem**: Current structures can't support algorithmic processing
**Solution**: Design for computational efficiency

```rust
// Replace manual processing with algorithmic state
#[account]
pub struct AuctionState {
    pub timeslot: Pubkey,
    pub clearing_price: u64,
    pub total_cleared_quantity: u64,
    pub total_revenue: u64,
    pub winning_bids_count: u32,
    pub participating_sellers_count: u32,
    pub status: AuctionStatus, // Processing, Cleared, Settled, Failed
    pub clearing_timestamp: i64,
}

// Efficient bid aggregation by price level
#[account]
pub struct PriceLevelAggregate {
    pub timeslot: Pubkey,
    pub price: u64,
    pub total_quantity: u64,
    pub bid_count: u16,
    pub cumulative_quantity: u64, // running sum for demand curve
}

// Track individual bid outcomes
#[account]
pub struct BidOutcome {
    pub buyer: Pubkey,
    pub timeslot: Pubkey,
    pub original_bid_price: u64,
    pub original_quantity: u64,
    pub filled_quantity: u64,
    pub refund_amount: u64,
    pub settlement_status: SettlementStatus,
}
```

### 3. Atomic Settlement System

**Problem**: Current system requires multiple separate transactions, creating inconsistency risks
**Solution**: Atomic multi-party settlement

**Key Features:**
- Single transaction to complete entire auction
- Automatic rollback if any settlement fails
- Verifiable mathematical correctness
- Gas-efficient batch processing

## Critical Implementation Guidelines

### ⚠️ AVOID THESE COMMON MISTAKES ⚠️

1. **DO NOT** assume you can iterate through all accounts in a single transaction
   - Solana has compute limits (~200k CU per transaction)
   - Design for batch processing across multiple transactions
   - Use continuation patterns for large datasets

2. **DO NOT** ignore account size limitations
   - Single account max: ~10KB
   - Design pagination for large bid books
   - Use multiple accounts for large datasets

3. **DO NOT** create circular dependencies between instructions
   - Each instruction must be independently callable
   - Avoid requiring specific call sequences that can break

4. **DO NOT** use floating-point arithmetic
   - All calculations must use integer math only
   - Handle precision carefully with basis points
   - Always check for overflow/underflow

5. **DO NOT** assume linear complexity is acceptable
   - O(n²) algorithms will fail with large bid books
   - Use efficient sorting and aggregation
   - Consider compute cost of every operation

### 🎯 ESSENTIAL SUCCESS CRITERIA

**Before you start coding, design solutions for:**

1. **Scalability**: How will your clearing algorithm handle 10,000 bids?
2. **Atomicity**: How do you ensure partial settlement failures don't corrupt state?
3. **Verifiability**: How can external parties verify clearing price calculation?
4. **Gas Efficiency**: How do you minimize transaction costs for users?
5. **Correctness**: How do you guarantee mathematical accuracy under all conditions?

## Detailed Technical Specifications

### Clearing Algorithm Specification

**Input**: Timeslot in "Sealed" status with committed supply and placed bids
**Output**: Determined clearing price, quantity allocations, settlement instructions

**Process Flow:**
1. **Validation Phase**
   - Verify timeslot is properly sealed
   - Confirm all escrows have correct balances
   - Validate bid and supply data integrity

2. **Data Aggregation Phase**
   - Collect all bids from linked list of BidPages
   - Aggregate bids by price level (reduce redundant processing)
   - Sort supply commitments by reserve price
   - Calculate cumulative demand and supply curves

3. **Market Clearing Phase**
   - Find intersection of supply/demand curves
   - Determine clearing price and total quantity
   - Handle edge cases (no clearing, insufficient supply, no demand)

4. **Allocation Phase**
   - Allocate supply using merit order
   - Determine winning bids and fill quantities
   - Calculate individual buyer settlements
   - Prepare seller proceed calculations

5. **Settlement Preparation Phase**
   - Create settlement instructions for all parties
   - Verify total escrow balances match settlement amounts
   - Generate audit trail data

### Error Handling Requirements

**Your implementation MUST handle these scenarios:**

1. **No Market Clearing**: All reserve prices > highest bid
2. **Oversupply**: More supply than demand at any price
3. **Undersupply**: More demand than available supply
4. **Computation Limits**: Bid book too large for single transaction
5. **Account Limits**: Too many participants for single settlement
6. **Precision Errors**: Rounding in quantity allocations
7. **Escrow Mismatches**: Token balance inconsistencies

### Mathematical Correctness Requirements

**Your implementation MUST maintain these invariants:**

```rust
// Verify these equations hold after clearing:
assert!(total_buyer_payments == total_seller_proceeds + protocol_fees);
assert!(total_energy_distributed == total_energy_committed);
assert!(sum_of_all_refunds == total_escrow - total_buyer_payments);
assert!(clearing_price >= minimum_reserve_price);
assert!(allocated_quantity <= committed_supply);
```

## Implementation Checklist

Before submitting your solution, verify:

- [ ] **Algorithm Completeness**: Does your solution actually determine clearing prices algorithmically?
- [ ] **Multi-Seller Support**: Can multiple sellers participate in a single auction?
- [ ] **Bid Processing**: Are all bids processed to determine winners/losers?
- [ ] **Atomic Settlement**: Can the entire auction settle in one logical operation?
- [ ] **Error Recovery**: What happens when things go wrong?
- [ ] **Gas Efficiency**: Will this work with realistic auction sizes?
- [ ] **Mathematical Accuracy**: Do all the numbers add up correctly?
- [ ] **State Consistency**: Is the contract state always coherent?

## Debugging & Problem-Solving Approach

**When you encounter issues:**

1. **Step Back and Analyze Root Cause**
   - Don't immediately try the same approach with minor tweaks
   - Question your fundamental assumptions
   - Consider if you're solving the right problem

2. **Test Your Logic Incrementally**
   - Start with simple cases (2 bids, 1 seller)
   - Gradually increase complexity
   - Verify mathematics at each step

3. **Consider Alternative Approaches**
   - If account iterations fail, try batch processing
   - If compute limits hit, try multi-transaction patterns
   - If complexity grows, try simpler algorithms

4. **Validate Against Real Requirements**
   - Does your solution actually work for 100 sellers?
   - Can it handle 5000 bids efficiently?
   - Is it economically correct under edge cases?

## Success Deliverables

**Your Phase 1 implementation must include:**

1. **Complete Rust Code**: Full Anchor program with all required instructions
2. **Algorithm Documentation**: Detailed explanation of clearing logic
3. **Test Cases**: Unit tests covering normal and edge cases
4. **Gas Analysis**: Estimated compute costs for typical auctions
5. **Mathematical Proofs**: Verification that invariants hold
6. **Migration Plan**: How to upgrade from current MVP

**Remember**: This is the foundation for a production energy trading system. Correctness and robustness are more important than feature completeness. Build something that works reliably rather than something that has many features but fails under stress.

## Final Notes

- The energy sector requires extremely high reliability - bugs can cause real financial losses
- Think like you're building infrastructure that will handle millions in daily trading volume
- Every edge case you don't handle will eventually occur in production
- Prioritize mathematical correctness over performance optimizations
- Design for auditability - regulators will examine this code